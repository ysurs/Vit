{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "##### Testing mha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mha import muliheaded_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mha=muliheaded_attention(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the module list output. We based on the number of heads we pass, we will have that many linear layers.\n",
    "testing_mha.q_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2625,  0.2740, -0.2138,  0.6563],\n",
      "         [ 0.2145, -0.5587,  0.0124,  0.6617],\n",
      "         [ 1.4776,  0.0247,  0.1867,  0.4367],\n",
      "         [-0.4658, -1.9022,  1.7393,  1.5262],\n",
      "         [-0.6221, -0.2175,  0.5872, -0.6206]],\n",
      "\n",
      "        [[ 0.1950,  0.6210, -1.5737,  1.7337],\n",
      "         [-0.9654,  0.8480,  1.0328, -0.8368],\n",
      "         [-1.5797, -1.4777,  0.1693,  0.0318],\n",
      "         [ 0.4615,  1.2474,  0.1352,  0.2735],\n",
      "         [-0.1720,  1.0442,  0.9636,  1.7562]]])\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.1146, -0.6354],\n",
      "        [-0.0770, -0.6512],\n",
      "        [ 0.1110, -0.7642],\n",
      "        [-0.1764, -0.5866],\n",
      "        [-0.1533, -0.6099]], grad_fn=<MmBackward0>)\n",
      "tensor([[-1.2227, -0.0050],\n",
      "        [-1.2072, -0.0021],\n",
      "        [-1.1608,  0.0028],\n",
      "        [-1.2190,  0.0178],\n",
      "        [-1.0228,  0.0423]], grad_fn=<MmBackward0>)\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.4493, -0.4046],\n",
      "        [-0.7134, -0.2643],\n",
      "        [-0.5432, -0.3444],\n",
      "        [-0.4751, -0.3930],\n",
      "        [-0.5797, -0.3361]], grad_fn=<MmBackward0>)\n",
      "tensor([[-0.8509, -0.4479],\n",
      "        [-0.9687,  0.5559],\n",
      "        [-0.9974,  0.0249],\n",
      "        [-0.9951, -0.0444],\n",
      "        [-0.9823, -0.2094]], grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 4])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A random tensor representing 1 image, 5 patches and embedding size of each patch to be 4\n",
    "testing_tensor=torch.randn(2,5,4)\n",
    "print(testing_tensor)\n",
    "testing_mha(testing_tensor).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output says that 2 heads will perform calculations on 5 patches where embedding size is 4. Since we have 2 heads, the embedding will be broken down into size of 2 and 2 for each head."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing out patchify function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 49, 16])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vit_model import patchify, ViT\n",
    "\n",
    "# Simulating an input where we have 3 images, each has 3 color channels. Each image has shape 4,4\n",
    "# testing_patchfy=torch.randn(3,3,4,4)\n",
    "testing_patchfy=torch.randn(7,1,28,28)\n",
    "\n",
    "# The output in this case implies, each image has been broken down into 4 patches. Each patch has embedding dim=12\n",
    "patchify(testing_patchfy,7).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Testing out Vit class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 49, 16])\n",
      "torch.Size([7, 50, 8])\n"
     ]
    }
   ],
   "source": [
    "myvit=ViT()\n",
    "# myvit(testing_patchfy).shape\n",
    "re=myvit(testing_patchfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 8])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cls=nn.Parameter(torch.ones(1,16))\n",
    "\n",
    "cls_input=[torch.cat((test_cls,p_s),dim=0) for p_s in re]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          1.0000e+00],\n",
       "        [-1.1258e+00, -1.1524e+00, -2.5058e-01, -4.3388e-01,  1.3894e+00,\n",
       "          1.5863e+00,  9.4630e-01, -8.4368e-01, -4.4622e-01,  7.4402e-01,\n",
       "          1.5210e+00,  3.4105e+00,  8.4189e-01, -4.0003e-01,  1.0395e+00,\n",
       "          3.5815e-01],\n",
       "        [ 8.4871e-01,  6.9201e-01, -3.1601e-01, -2.1152e+00, -6.1358e-01,\n",
       "          3.1593e-02, -4.9268e-01,  2.4841e-01, -1.5312e+00, -1.2341e+00,\n",
       "          1.8197e+00, -5.5153e-01, -2.4600e-01,  2.3025e+00, -1.8817e+00,\n",
       "         -4.9727e-02],\n",
       "        [ 3.2227e-01, -1.2633e+00,  3.4998e-01,  3.0813e-01,  4.3970e-01,\n",
       "          1.1241e-01,  6.4079e-01,  4.4116e-01, -5.6925e-01,  9.1997e-01,\n",
       "          1.1108e+00,  1.2899e+00, -1.0450e+00, -9.5650e-01,  3.3532e-02,\n",
       "          7.1009e-01],\n",
       "        [ 1.1984e-01,  1.2377e+00,  1.1168e+00, -2.4728e-01, -1.0231e-01,\n",
       "          7.9244e-01, -2.8967e-01,  5.2507e-02, -1.4782e+00,  2.5672e+00,\n",
       "         -4.7312e-01,  3.3555e-01,  1.6459e+00, -1.3602e+00,  3.4457e-01,\n",
       "          5.1987e-01],\n",
       "        [-1.3527e+00, -1.6959e+00,  5.6665e-01,  7.9351e-01,  5.2286e-01,\n",
       "          2.3022e+00, -1.4689e+00, -1.5867e+00, -1.6293e+00, -5.4974e-01,\n",
       "         -4.7983e-01, -4.9968e-01, -2.6133e+00, -1.6965e+00, -2.2824e-01,\n",
       "          2.7995e-01],\n",
       "        [ 5.9884e-01, -1.5551e+00, -3.4136e-01,  1.8530e+00, -6.7309e-01,\n",
       "          8.7283e-01,  1.0554e+00,  1.7784e-01, -1.0670e+00,  1.1149e+00,\n",
       "         -1.4067e-01,  8.0575e-01,  2.4693e-01,  7.6887e-02,  3.3801e-01,\n",
       "          4.5440e-01],\n",
       "        [ 7.5019e-01, -5.8550e-01, -1.7340e-01,  1.8348e-01, -2.3034e-01,\n",
       "         -3.9175e-01,  5.4329e-01, -3.9516e-01, -9.3348e-02,  6.8705e-01,\n",
       "         -8.3832e-01,  8.9182e-04,  4.5694e-01, -8.6537e-01,  7.8131e-01,\n",
       "         -9.2679e-01],\n",
       "        [-2.1883e-01, -2.4351e+00, -7.2915e-02, -3.3987e-02, -1.0209e-01,\n",
       "         -1.0335e+00, -3.1264e-01,  2.4579e-01,  3.1405e-01,  2.1333e-01,\n",
       "         -1.2005e-01,  3.6046e-01,  1.7151e-01,  8.7604e-01, -2.8709e-01,\n",
       "          1.0216e+00],\n",
       "        [ 9.6252e-01,  3.4917e-01, -9.2146e-01, -5.6195e-02, -2.5964e-01,\n",
       "          1.1834e-01,  2.4396e-01,  1.1646e+00, -3.1404e-01, -1.0787e+00,\n",
       "          2.4081e-01, -1.3962e+00, -7.4395e-02, -1.0922e+00,  3.9203e-01,\n",
       "          5.9453e-01],\n",
       "        [-6.2270e-01, -4.6372e-01,  1.9218e+00, -4.0255e-01,  2.8858e-01,\n",
       "          3.8660e-01, -2.0106e-01, -1.1793e-01, -6.6145e-02, -3.5836e-01,\n",
       "         -1.5616e+00, -3.5464e-01,  6.6227e-01, -1.2063e+00,  6.0744e-01,\n",
       "         -5.4716e-01],\n",
       "        [ 1.2390e-01,  1.1648e+00,  9.2337e-01,  1.3873e+00,  1.9220e-01,\n",
       "         -7.7216e-01, -1.9003e+00,  1.3068e-01,  1.0811e+00,  1.3148e-01,\n",
       "          1.5735e+00,  7.8143e-01,  1.1711e+00,  9.7496e-02,  9.6337e-01,\n",
       "          8.4032e-01],\n",
       "        [-8.8338e-01, -4.1891e-01, -8.0483e-01,  5.6561e-01, -7.0429e-01,\n",
       "          3.1472e-01,  1.5739e-01,  3.8536e-01, -1.0787e+00, -7.2091e-01,\n",
       "          1.4708e+00,  2.7564e-01, -1.2537e+00,  9.8684e-01, -4.9466e-01,\n",
       "         -1.2830e+00],\n",
       "        [ 6.1036e-01,  4.6688e-01,  1.9507e+00, -1.0631e+00,  9.6715e-01,\n",
       "         -9.9108e-01,  3.0161e-01, -1.0732e-01,  6.6678e-01, -9.9439e-01,\n",
       "         -1.1894e+00, -1.1959e+00,  9.5522e-01,  1.2836e+00, -6.6586e-01,\n",
       "          5.6513e-01],\n",
       "        [-7.7326e-02,  1.1640e-01, -5.9399e-01, -1.2439e+00,  9.9846e-01,\n",
       "         -4.9871e-01,  7.6111e-01,  6.1830e-01, -5.5963e-01,  5.3347e-01,\n",
       "          4.0689e-01,  3.9459e-01,  2.8770e-01, -3.3375e-02, -1.0619e+00,\n",
       "         -1.1443e-01],\n",
       "        [-3.4334e-01,  1.5713e+00,  1.9161e-01,  3.7994e-01, -8.7074e-01,\n",
       "          1.4474e-01,  1.9029e+00,  3.9040e-01, -2.3494e-02,  1.1717e+00,\n",
       "          3.9869e-01, -1.9872e-01,  1.0759e-01, -1.0715e+00, -1.1665e-01,\n",
       "         -1.0170e+00],\n",
       "        [-1.4476e-01,  6.3762e-01, -2.8129e-01, -1.3299e+00, -3.9373e-02,\n",
       "         -8.0147e-01, -4.9554e-01, -3.6151e-01, -1.1559e+00, -3.1667e-01,\n",
       "          9.4030e-01, -1.1470e+00, -1.1980e+00,  4.7844e-01, -1.2295e+00,\n",
       "         -1.3700e+00],\n",
       "        [-1.4201e-01, -5.3415e-01, -5.2338e-01,  8.6150e-01,  5.8511e-01,\n",
       "         -1.1560e+00, -1.4336e-01, -1.9474e-01,  5.5880e-01,  7.9176e-01,\n",
       "         -1.8468e-01, -7.3177e-01,  1.5435e+00, -3.3207e-02, -4.1863e-01,\n",
       "         -2.5560e-01],\n",
       "        [-8.8696e-01,  8.3877e-01,  1.1529e+00, -1.7611e+00, -8.5563e-02,\n",
       "          1.3945e+00,  5.9690e-01, -4.8285e-01, -8.0652e-02, -9.8006e-01,\n",
       "          6.0492e-02, -4.8895e-01, -1.2923e-01, -5.4595e-02,  4.0835e-01,\n",
       "          1.1264e+00],\n",
       "        [-1.4777e+00, -1.7557e+00,  7.6166e-02, -1.0786e+00, -3.6610e-01,\n",
       "         -1.3271e+00,  1.6953e+00,  2.0655e+00, -8.1373e-01,  8.1999e-01,\n",
       "         -6.3317e-01,  1.2948e+00,  1.9351e+00,  1.0077e+00,  1.0046e+00,\n",
       "         -4.3352e-01],\n",
       "        [ 1.4403e+00, -1.1059e-01,  5.7686e-01, -1.6917e-01, -2.3396e-01,\n",
       "          7.0732e-01,  5.8005e-01,  2.6830e-01,  1.4628e+00, -6.2043e-01,\n",
       "          9.8839e-01, -4.3218e-01, -1.2426e+00,  1.2846e+00,  2.4377e-01,\n",
       "          5.3037e-01],\n",
       "        [-6.4025e-02,  1.0384e+00,  9.0682e-01, -4.7551e-01, -2.0589e+00,\n",
       "          5.3402e-01, -5.3539e-01, -8.6367e-01, -6.2322e-01, -2.1625e-01,\n",
       "         -4.8868e-01,  7.8696e-01, -1.4531e-02, -2.2357e+00,  1.4660e+00,\n",
       "         -1.2191e+00],\n",
       "        [ 6.4423e-01,  3.9300e+00, -1.2442e-01,  2.9534e-01, -8.8768e-01,\n",
       "         -3.1832e-01, -3.3440e-01,  4.5428e-01,  1.4502e+00,  4.1015e+00,\n",
       "          1.1182e+00, -1.5668e+00, -2.7926e-01, -2.7690e-01,  7.4893e-01,\n",
       "         -6.4346e-01],\n",
       "        [ 3.8265e-01, -5.4972e-01, -9.9404e-01,  1.3459e+00,  4.9895e-01,\n",
       "          8.7800e-01,  3.8944e-01,  1.4625e+00, -6.9898e-01,  5.7439e-01,\n",
       "          1.2381e+00, -6.4054e-01, -9.5176e-01,  2.7152e-01,  6.7158e-01,\n",
       "          1.8500e+00],\n",
       "        [ 1.9457e+00, -1.2904e+00, -2.3495e+00, -2.0689e+00,  4.7951e-01,\n",
       "         -5.3340e-01, -3.4651e-02,  6.5730e-01, -7.6447e-01,  2.4084e-01,\n",
       "          1.6643e-01, -2.2318e+00,  1.1910e+00, -5.8986e-01,  9.6469e-01,\n",
       "         -1.5094e+00],\n",
       "        [ 9.0942e-01, -6.9462e-01,  1.9595e+00, -1.1038e+00, -3.1122e-01,\n",
       "         -5.6200e-01, -4.8349e-01, -1.2721e+00,  1.3892e+00, -5.0233e-01,\n",
       "          1.6797e+00, -1.0240e+00,  2.2557e+00,  1.2288e+00, -4.8546e-01,\n",
       "          4.5357e-01],\n",
       "        [ 5.4114e-01,  1.5390e+00,  1.0860e+00,  1.2464e+00, -1.7402e-01,\n",
       "          5.5412e-01, -1.8166e-01, -2.3447e-01,  1.6859e+00, -1.2177e+00,\n",
       "          7.6496e-01,  1.1971e+00,  1.3514e+00,  4.3393e-01, -5.1325e-01,\n",
       "         -1.8603e-01],\n",
       "        [ 1.1508e-01,  1.6193e+00,  4.6369e-01,  1.3007e+00,  2.9420e-01,\n",
       "          7.9732e-01,  1.2642e+00,  9.3549e-01, -7.1279e-01, -6.5575e-02,\n",
       "          2.2050e+00,  1.7852e+00,  2.7566e-01,  1.0969e-01,  3.5942e-01,\n",
       "         -7.5374e-01],\n",
       "        [ 8.7323e-01,  6.5127e-02,  7.7324e-01, -9.7014e-01,  5.4546e-01,\n",
       "         -1.5374e+00,  3.1244e-01,  7.4006e-01, -1.1841e-02,  9.7967e-01,\n",
       "         -1.0661e+00,  1.7720e+00,  2.2940e-01, -2.5444e-01,  1.5800e+00,\n",
       "         -2.4436e-01],\n",
       "        [-1.1991e+00, -2.5686e-02,  1.8024e+00, -1.0597e+00,  2.1601e-01,\n",
       "         -9.1608e-01,  1.5599e+00, -3.1537e+00, -1.9062e-01,  7.1665e-01,\n",
       "         -2.0002e+00, -2.4097e+00,  3.6156e-02, -3.4222e-01, -3.8169e-01,\n",
       "         -5.6879e-02],\n",
       "        [ 3.4028e+00, -5.6867e-01, -4.7549e-01,  1.7432e+00, -5.6110e-01,\n",
       "         -4.3030e-01, -3.3323e-01, -1.5464e+00,  2.1942e-01, -1.6989e+00,\n",
       "          1.3094e+00, -1.6613e+00,  8.4362e-01,  6.8287e-01,  3.3944e+00,\n",
       "         -1.6688e+00],\n",
       "        [-2.0441e-01, -3.1641e-01,  1.2937e+00,  1.3453e+00, -1.4717e-02,\n",
       "          1.2251e+00,  1.5936e+00, -1.6315e+00, -5.4607e-01, -6.3018e-01,\n",
       "         -6.3465e-01,  9.7466e-01,  5.1086e-01, -2.8598e-01,  3.3505e-01,\n",
       "          1.1719e+00],\n",
       "        [ 1.9394e-01,  1.5717e+00, -3.8274e-01,  1.3951e+00, -5.6877e-02,\n",
       "          6.2966e-01,  2.7117e-01, -6.8598e-01,  2.0984e-01,  2.9890e-02,\n",
       "          1.7092e+00, -7.2576e-01,  1.2955e+00,  8.9086e-01, -4.8985e-01,\n",
       "         -1.1727e+00],\n",
       "        [ 3.4275e-01, -1.6045e+00, -5.8731e-01,  6.0039e-01, -1.0918e+00,\n",
       "          1.6797e+00, -8.8082e-01,  5.8003e-01, -7.7354e-01,  5.9621e-01,\n",
       "         -1.2504e+00,  1.1456e+00, -6.8705e-01, -2.3349e+00,  9.4041e-02,\n",
       "         -2.0208e-01],\n",
       "        [ 4.3780e-01, -9.6455e-02,  3.3027e-01, -1.8752e-01,  3.6423e-01,\n",
       "          8.8134e-02, -1.3069e+00, -7.0637e-01,  7.3934e-01,  1.2532e+00,\n",
       "         -4.4452e-01,  8.1845e-01, -5.9524e-02,  2.0118e+00, -3.3679e-01,\n",
       "          3.2598e-01],\n",
       "        [-1.4271e+00,  5.9255e-01, -1.1582e+00,  3.5761e-02, -1.6422e-01,\n",
       "         -9.7147e-01, -1.0308e+00,  6.4728e-01, -8.1802e-01,  3.6032e-01,\n",
       "         -1.6146e+00, -2.4734e+00,  5.3520e-01,  1.9733e+00, -2.0751e-01,\n",
       "         -3.0574e-02],\n",
       "        [ 1.2673e-01,  5.5466e-03,  7.9434e-01,  4.0715e-01, -5.6417e-01,\n",
       "         -2.7400e-01,  1.3978e-01,  5.0856e-01, -7.6502e-01, -4.7497e-01,\n",
       "         -4.9526e-01, -1.9836e-01,  5.4501e-01,  1.5412e+00,  6.0024e-01,\n",
       "         -3.3801e-01],\n",
       "        [-3.6090e-01,  1.3103e+00, -9.6505e-01,  8.8061e-01,  2.7710e-01,\n",
       "         -9.8125e-01,  8.8885e-01,  1.5690e+00,  2.2149e+00, -1.3669e-01,\n",
       "         -1.0182e+00,  1.7841e-01,  4.0466e-01,  8.9313e-01, -1.4541e+00,\n",
       "          1.1875e+00],\n",
       "        [-1.0247e-01, -6.7701e-01, -4.1066e-01, -1.6186e+00, -8.1853e-02,\n",
       "         -3.4940e-01,  2.0243e-01, -2.8838e-01, -5.1359e-01, -5.6443e-01,\n",
       "         -9.1837e-01, -7.4956e-01, -2.9952e-01,  2.2963e+00,  3.3055e-01,\n",
       "          2.1748e+00],\n",
       "        [ 5.0791e-01,  2.3230e+00,  2.2978e-01, -5.2965e-01,  1.4830e-01,\n",
       "          2.4187e+00,  1.3279e+00, -2.6386e-01, -9.4933e-02,  1.1009e+00,\n",
       "          1.3105e+00, -2.9285e-01, -1.2460e+00,  2.4966e+00, -7.0688e-01,\n",
       "          1.1504e+00],\n",
       "        [-8.7331e-01,  4.2614e-03, -1.2579e+00, -1.0845e+00,  3.6447e-01,\n",
       "          2.5440e+00, -2.6895e+00,  2.4426e+00, -7.8834e-01, -1.6952e-01,\n",
       "         -2.1749e+00,  7.2025e-01, -5.4977e-01,  8.1552e-01,  2.0005e+00,\n",
       "         -4.3935e-01],\n",
       "        [ 7.5298e-01,  3.2365e-01, -2.7501e-01,  1.3056e+00,  1.0375e-02,\n",
       "         -9.9649e-01,  9.7850e-01, -4.4144e-01,  2.8545e-01,  2.2903e-01,\n",
       "          1.2833e+00, -1.3792e+00, -4.3190e-01, -4.7293e-01,  3.2564e-01,\n",
       "         -9.7362e-01],\n",
       "        [ 2.1175e-01,  2.7196e-01, -9.2684e-01, -2.7330e+00, -2.6104e-01,\n",
       "          7.9798e-01, -1.1071e+00,  2.3306e+00,  5.4076e-01, -9.4781e-01,\n",
       "          2.0214e-01, -3.5075e-01,  7.9789e-01, -5.7330e-01,  2.0605e-01,\n",
       "          2.1374e-01],\n",
       "        [ 9.5440e-01,  7.3306e-01, -1.4552e+00, -2.0458e+00,  1.8480e+00,\n",
       "         -2.3950e+00,  4.0770e-01, -1.6989e-01, -2.0546e+00,  5.2591e-01,\n",
       "          5.9946e-01, -4.0782e-01, -3.4832e-01,  1.2075e+00, -6.4783e-01,\n",
       "          5.2652e-01],\n",
       "        [-1.7708e-01,  6.2405e-01, -1.6889e+00,  8.1758e-01,  5.8418e-01,\n",
       "          1.0504e+00,  1.2856e+00, -1.6165e+00,  4.5302e-01, -3.9179e-01,\n",
       "          2.1403e+00, -2.0620e-01, -9.5079e-01, -2.1456e+00,  3.8271e-01,\n",
       "         -4.0975e-01],\n",
       "        [-3.8960e-01,  1.2776e+00,  5.1468e-01,  3.4852e-01, -7.6896e-01,\n",
       "         -1.2205e+00,  5.7313e-01,  6.9920e-01, -9.8389e-02,  4.8547e-01,\n",
       "          7.0757e-01,  4.3065e-02, -7.3860e-01,  1.6553e+00,  5.2037e-01,\n",
       "         -2.3262e-01],\n",
       "        [-1.0379e+00, -9.5869e-01,  9.1817e-01,  4.8880e-01,  2.5106e-01,\n",
       "          2.7845e-01, -9.4635e-02,  1.6104e+00, -4.3944e-01, -6.7611e-01,\n",
       "          1.7389e+00, -9.4229e-01,  4.9742e-01,  2.6852e-01,  1.4769e+00,\n",
       "          3.5480e-01],\n",
       "        [ 9.8393e-01,  9.9614e-01, -1.1658e+00, -5.8537e-01, -1.2166e-01,\n",
       "         -1.3941e+00, -9.0479e-01, -3.4670e-01, -1.0646e+00, -2.2971e-01,\n",
       "         -1.2564e+00,  5.5701e-01,  1.6247e+00,  5.9342e-01, -1.7254e+00,\n",
       "         -6.2202e-01],\n",
       "        [-1.8619e-01, -1.2374e+00,  1.1839e+00, -1.9545e-01,  7.0494e-01,\n",
       "          3.0545e-02, -8.5424e-01,  5.3882e-01,  1.5761e-01,  1.0271e+00,\n",
       "          1.2293e+00, -1.2231e-03, -6.2494e-03,  8.9520e-01, -7.6999e-03,\n",
       "          4.5172e-02],\n",
       "        [-1.3366e+00,  1.0511e+00, -1.0269e+00, -2.8750e-01, -5.2649e-01,\n",
       "         -1.3320e+00,  1.5451e+00,  4.0863e-01, -1.8095e+00,  6.9256e-01,\n",
       "          1.1982e+00,  1.3167e+00,  5.7934e-01, -1.5825e+00, -5.8779e-01,\n",
       "         -1.1398e-01]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(cls_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cls_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myvit.patch_embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapter_b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
